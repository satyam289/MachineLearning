{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vq52wa0AaOOm"
      },
      "source": [
        "# TF-IDF \n",
        "### Mobile Review"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UR5JQB6_pjTP"
      },
      "source": [
        "### Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uazcUKCqpjTP"
      },
      "source": [
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47LuiF46pjTQ"
      },
      "source": [
        "### Import required packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ADzXQmpspjTQ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import re\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from bs4 import BeautifulSoup\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.metrics import classification_report\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L7g0owtrOUeX"
      },
      "source": [
        "**Load dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "T4lSCu4gpjTS"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Product Name</th>\n",
              "      <th>Brand Name</th>\n",
              "      <th>Price</th>\n",
              "      <th>Rating</th>\n",
              "      <th>Reviews</th>\n",
              "      <th>Review Votes</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
              "      <td>Samsung</td>\n",
              "      <td>199.99</td>\n",
              "      <td>5</td>\n",
              "      <td>feel lucky found used phone us used hard all, ...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>POSITIVE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
              "      <td>Samsung</td>\n",
              "      <td>199.99</td>\n",
              "      <td>4</td>\n",
              "      <td>nice phone, nice grade pantach revue. clean se...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>POSITIVE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
              "      <td>Samsung</td>\n",
              "      <td>199.99</td>\n",
              "      <td>5</td>\n",
              "      <td>pleased</td>\n",
              "      <td>0.0</td>\n",
              "      <td>POSITIVE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
              "      <td>Samsung</td>\n",
              "      <td>199.99</td>\n",
              "      <td>4</td>\n",
              "      <td>works good goes slow sometimes good phone love</td>\n",
              "      <td>0.0</td>\n",
              "      <td>POSITIVE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...</td>\n",
              "      <td>Samsung</td>\n",
              "      <td>199.99</td>\n",
              "      <td>4</td>\n",
              "      <td>great phone replace lost phone. thing volume b...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>POSITIVE</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                        Product Name Brand Name   Price  \\\n",
              "0  \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...    Samsung  199.99   \n",
              "1  \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...    Samsung  199.99   \n",
              "2  \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...    Samsung  199.99   \n",
              "3  \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...    Samsung  199.99   \n",
              "4  \"CLEAR CLEAN ESN\" Sprint EPIC 4G Galaxy SPH-D7...    Samsung  199.99   \n",
              "\n",
              "   Rating                                            Reviews  Review Votes  \\\n",
              "0       5  feel lucky found used phone us used hard all, ...           1.0   \n",
              "1       4  nice phone, nice grade pantach revue. clean se...           0.0   \n",
              "2       5                                            pleased           0.0   \n",
              "3       4     works good goes slow sometimes good phone love           0.0   \n",
              "4       4  great phone replace lost phone. thing volume b...           0.0   \n",
              "\n",
              "  Sentiment  \n",
              "0  POSITIVE  \n",
              "1  POSITIVE  \n",
              "2  POSITIVE  \n",
              "3  POSITIVE  \n",
              "4  POSITIVE  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load dataset\n",
        "_df = pd.read_csv('../data/amazon_reviews_processed.csv').dropna()\n",
        "_df.drop(_df.columns[_df.columns.str.contains('unnamed',case = False)],axis = 1, inplace = True)\n",
        "_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Product Name</th>\n",
              "      <th>Reviews</th>\n",
              "      <th>Rating</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>SAMSUNG Galaxy M01 (Black, 32 GB)</td>\n",
              "      <td>recently gifted cell dad... obvious choice 1. ...</td>\n",
              "      <td>4</td>\n",
              "      <td>POSITIVE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>SAMSUNG Galaxy M01 (Black, 32 GB)</td>\n",
              "      <td>truly satisfied performance phone.first budget...</td>\n",
              "      <td>5</td>\n",
              "      <td>POSITIVE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>SAMSUNG Galaxy M01 (Black, 32 GB)</td>\n",
              "      <td>gifted mom... good normal user... heavy user g...</td>\n",
              "      <td>4</td>\n",
              "      <td>POSITIVE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>SAMSUNG Galaxy M01 (Black, 32 GB)</td>\n",
              "      <td>good phone extremely liked good perfomance sup...</td>\n",
              "      <td>5</td>\n",
              "      <td>POSITIVE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>SAMSUNG Galaxy M01 (Black, 32 GB)</td>\n",
              "      <td>phone good simple purpose still value money ma...</td>\n",
              "      <td>3</td>\n",
              "      <td>NEUTRAL</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                        Product Name  \\\n",
              "0  SAMSUNG Galaxy M01 (Black, 32 GB)   \n",
              "1  SAMSUNG Galaxy M01 (Black, 32 GB)   \n",
              "2  SAMSUNG Galaxy M01 (Black, 32 GB)   \n",
              "3  SAMSUNG Galaxy M01 (Black, 32 GB)   \n",
              "4  SAMSUNG Galaxy M01 (Black, 32 GB)   \n",
              "\n",
              "                                             Reviews  Rating Sentiment  \n",
              "0  recently gifted cell dad... obvious choice 1. ...       4  POSITIVE  \n",
              "1  truly satisfied performance phone.first budget...       5  POSITIVE  \n",
              "2  gifted mom... good normal user... heavy user g...       4  POSITIVE  \n",
              "3  good phone extremely liked good perfomance sup...       5  POSITIVE  \n",
              "4  phone good simple purpose still value money ma...       3   NEUTRAL  "
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "_df2 = pd.read_csv('../data/flipkar_reviews_processed.csv').dropna()\n",
        "_df2.drop(_df2.columns[_df2.columns.str.contains('unnamed',case = False)],axis = 1, inplace = True)\n",
        "_df2.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load dataset\n",
        "_df = pd.read_csv('../data/mobile_reviews.csv').dropna()\n",
        "_df.drop(_df.columns[_df.columns.str.contains('unnamed',case = False)],axis = 1, inplace = True)\n",
        "_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "_df[\"Product Name\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "5    347280\n",
              "4    108560\n",
              "1     91000\n",
              "3     50200\n",
              "2     32399\n",
              "Name: Rating, dtype: int64"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "_df[\"Rating\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "POSITIVE    455840\n",
              "NEGATIVE    123399\n",
              "NEUTRAL      50200\n",
              "Name: Sentiment, dtype: int64"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "_df[\"Sentiment\"].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**TF-IDF**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "def contractions(s):\n",
        " s = re.sub(r\"won’t\", \"will not\",s)\n",
        " s = re.sub(r\"can\\’t\", \"can not\",s)\n",
        " s = re.sub(r\"n\\’t\", \" not\", s)\n",
        " s= re.sub(r\"\\’re\", \" are\", s)\n",
        " s = re.sub(r\"\\’s\", \" is\", s)\n",
        " s = re.sub(r\"\\’ll\", \" will\", s)\n",
        " s = re.sub(r\"\\’t\", \" not\", s)\n",
        " s = re.sub(r\"\\’ve\", \" have\", s)\n",
        " s = re.sub(r\"\\’m\", \" am\", s)\n",
        " return s"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "def preprocess(df):\n",
        "    #lower case word by word\n",
        "    df[\"pre_process\"] = df[\"Reviews\"].apply(lambda x: \"\".join(x.lower() for x in str(x).split()))\n",
        "    #Beautify Text\n",
        "    df[\"pre_process\"] = df[\"pre_process\"].apply(lambda x: BeautifulSoup(x).get_text())\n",
        "    #Remove URL\n",
        "    df[\"pre_process\"] = df[\"pre_process\"].apply(lambda x: re.sub(r\"http\\S+\", \"\", x))\n",
        "    #Expand contracted word\n",
        "    df[\"pre_process\"] = df[\"pre_process\"].apply(lambda x:contractions(x))\n",
        "    #Remove non-alpha characters\n",
        "    df[\"pre_process\"] = df[\"pre_process\"].apply(lambda x: \" \".join([re.sub(\"[^A-Za-z]+\",\"\", x) for x in nltk.word_tokenize(x)]))\n",
        "    #Remove the extra spaces between the word_s\n",
        "    df[\"pre_process\"] = df[\"pre_process\"].apply(lambda x: re.sub(\" +\", \" \", x))\n",
        "    stop = stopwords.words('english')\n",
        "    df[\"pre_process\"]= df[\"pre_process\"].apply(lambda x: \" \".join([x for x in x.split() if x not in stop]))\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    df[\"pre_process\"]= df[\"pre_process\"].apply(lambda x: \" \".join([lemmatizer.lemmatize(w) for w in nltk.word_tokenize(x)]))\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "_df = preprocess(_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "_df2 = preprocess(_df2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "POSITIVE    80184\n",
              "NEGATIVE    35903\n",
              "NEUTRAL     11787\n",
              "Name: Sentiment, dtype: int64"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "_df['Sentiment'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train:  (127874,) (127874,)  Test:  ((125852,), (125852,))\n"
          ]
        }
      ],
      "source": [
        "#X_train,X_test,Y_train, Y_test = train_test_split(_df[\"pre_process\"], _df[\"Sentiment\"], test_size=0.25, random_state=30)\n",
        "X_train = _df['pre_process']\n",
        "Y_train = _df['Sentiment']\n",
        "X_test = _df2['pre_process']\n",
        "Y_test = _df2['Sentiment']\n",
        "\n",
        "print(\"Train: \",X_train.shape,Y_train.shape,\" Test: \",(X_test.shape,Y_test.shape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "vectorizer= TfidfVectorizer()\n",
        "tf_x_train = vectorizer.fit_transform(X_train)\n",
        "tf_x_test = vectorizer.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(127874, 324316)"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf_x_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(125852, 324316)"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf_x_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "#SVM\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.utils import class_weight\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [],
      "source": [
        "SVMModel = Pipeline(steps=[('SVC', SVC(gamma='scale'))])\n",
        "param_grid= {'SVC__C': [0.1, 1],\n",
        "             'SVC__degree': [1]}\n",
        "\n",
        "BestSVMModel = GridSearchCV(SVMModel, param_grid, cv=5).fit(tf_x_train, Y_train)\n",
        "print(f'Best Parameters: {BestSVMModel.best_params_}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "model2 = SVC(gamma='scale', C=0.1, degree=1).fit(tf_x_train, Y_train)\n",
        "y_test_pred = model2.predict(tf_x_test)\n",
        "print(classification_report(Y_test, y_test_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_test_pred=BestSVMModel.predict(tf_x_test)\n",
        "print(classification_report(Y_test, y_test_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "LRModel = Pipeline(steps=[('logistic', LogisticRegression(random_state=0))])\n",
        "class_weights = class_weight.compute_class_weight('balanced', classes=np.unique(Y_train), y=Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1.18721741, 3.61624388, 0.53158569])"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Parameters: {'logistic__C': 10}\n"
          ]
        }
      ],
      "source": [
        "param_grid= {'logistic__C': [0.1, 1, 10]}\n",
        "BestLRModel2 = GridSearchCV(LRModel, param_grid, cv=5).fit(tf_x_train, Y_train)\n",
        "print(f'Best Parameters: {BestLRModel2.best_params_}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    NEGATIVE       0.54      0.08      0.13     21092\n",
            "     NEUTRAL       0.17      0.03      0.04     11063\n",
            "    POSITIVE       0.76      0.98      0.85     93697\n",
            "\n",
            "    accuracy                           0.74    125852\n",
            "   macro avg       0.49      0.36      0.34    125852\n",
            "weighted avg       0.67      0.74      0.66    125852\n",
            "\n"
          ]
        }
      ],
      "source": [
        "y_test_pred = BestLRModel2.predict(tf_x_test)\n",
        "print(classification_report(Y_test, y_test_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**N-gram**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for gram in range(2,5):\n",
        "  ng_vectorizer = CountVectorizer(ngram_range=(1, gram))\n",
        "  X_train_ng = ng_vectorizer.fit_transform(X_train)\n",
        "  X_test_ng = ng_vectorizer.transform(X_test)\n",
        "  clf_ng = MultinomialNB()\n",
        "  clf_ng.fit(X_train_ng, Y_train)\n",
        "\n",
        "  accuracy = clf_ng.score(X_test_ng, Y_test)\n",
        "  y_pred = clf_ng.predict(X_test_ng)\n",
        "  print(\"Number of features is %s, Accuracy for %s-gram is %s\" %(X_train_ng.shape[1], gram, accuracy))\n",
        "  print(classification_report(Y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM,Dense, Dropout\n",
        "from tensorflow.keras.layers import SpatialDropout1D\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
        "#import wordcloud"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "tweet_df = _df[_df['Sentiment'] != 'NEUTRAL']\n",
        "tweet_df2 = _df2[_df2['Sentiment'] != 'NEUTRAL']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "max_fatures = 2000\n",
        "embedding_vector_length = 32\n",
        "\n",
        "tokenizer = Tokenizer(num_words=max_fatures, split=' ')\n",
        "\n",
        "tokenizer.fit_on_texts(tweet_df['pre_process'].values)\n",
        "encoded_docs  = tokenizer.texts_to_sequences(tweet_df['pre_process'].values)\n",
        "X = pad_sequences(encoded_docs , maxlen=200)\n",
        "\n",
        "tokenizer.fit_on_texts(tweet_df2['pre_process'].values)\n",
        "encoded_docs2  = tokenizer.texts_to_sequences(tweet_df2['pre_process'].values)\n",
        "X2 = pad_sequences(encoded_docs2 , maxlen=200)\n",
        "\n",
        "vocab_size = len(tokenizer.word_index) + 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "sentiment_label = tweet_df.Sentiment.factorize()\n",
        "sentiment_label2 = tweet_df2.Sentiment.factorize()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, embedding_vector_length, input_length=200) )\n",
        "model.add(SpatialDropout1D(0.25))\n",
        "model.add(LSTM(50, dropout=0.5, recurrent_dropout=0.5))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy',optimizer='adam', metrics=['accuracy'])\n",
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train:  (116087,) 116087  Test:  (114789,) 114789\n"
          ]
        }
      ],
      "source": [
        "#X_train2, X_test2, Y_train2, Y_test2 = train_test_split(X,sentiment_label, test_size = 0.33, random_state = 42)\n",
        "X_train2 = X\n",
        "Y_train2 = sentiment_label[0]\n",
        "\n",
        "X_test2 = X2\n",
        "Y_test2 = sentiment_label2[0]\n",
        "print(\"Train: \", X_train2.shape,len(Y_train2),\" Test: \", X_test2.shape,len(Y_test2))\n",
        "\n",
        "callback = EarlyStopping(monitor='loss', patience=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3628/3628 [==============================] - 1260s 346ms/step - loss: 0.5939 - accuracy: 0.6966\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x1f15f47a8c0>"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(X, sentiment_label[0], epochs = 1, batch_size=32, callbacks=[callback])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.save('my_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3588/3588 [==============================] - 124s 34ms/step - loss: 0.5440 - accuracy: 0.8010\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.5439526438713074, 0.8010436296463013]"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.evaluate(X2,sentiment_label2[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "model = keras.models.load_model('my_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 200, 32)           9308640   \n",
            "                                                                 \n",
            " spatial_dropout1d_1 (Spatia  (None, 200, 32)          0         \n",
            " lDropout1D)                                                     \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 50)                16600     \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 50)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 51        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 9,325,291\n",
            "Trainable params: 9,325,291\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.36847445],\n",
              "       [0.36847445],\n",
              "       [0.369689  ],\n",
              "       ...,\n",
              "       [0.15601194],\n",
              "       [0.36847445],\n",
              "       [0.36847445]], dtype=float32)"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred = model.predict(X2)\n",
        "y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0, 0, 0, ..., 0, 1, 0], dtype=int64)"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sentiment_label2[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.36847445],\n",
              "       [0.36847445],\n",
              "       [0.369689  ],\n",
              "       ...,\n",
              "       [0.15601194],\n",
              "       [0.36847445],\n",
              "       [0.36847445]], dtype=float32)"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [],
      "source": [
        "some=np.round(y_pred).astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 179,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([2, 2, 2, ..., 2, 2, 2], dtype=int64)"
            ]
          },
          "execution_count": 179,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#predict_class = np.argmax(y_pred, axis=1)\n",
        "#predict_class = np.argmax(y_pred, axis=1)\n",
        "#predict_class = predict_class.tolist()\n",
        "#np.argmax(Y_test2, axis=1)\n",
        "#predict_class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.82      0.89    112417\n",
            "           1       0.01      0.13      0.03      2372\n",
            "\n",
            "    accuracy                           0.80    114789\n",
            "   macro avg       0.50      0.47      0.46    114789\n",
            "weighted avg       0.96      0.80      0.87    114789\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(classification_report(some, sentiment_label2[0]))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Tutorial_11_clustering.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
